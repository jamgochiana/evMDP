{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Electric Vehicle Charge Scheduling MDP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies\n",
    "\n",
    "You will need to install POMDPs and POMDPToolbox locally before being able to run this notebook. This can be done by running the following in your local Julia 1.0 REPL: \n",
    "    - Pkg.add(\"POMDPs\")\n",
    "    - Pkg.add(\"POMDPModelTools\")\n",
    "    - Pkg.add(\"POMDPSimulators\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using POMDPs, POMDPModelTools, POMDPSimulators, Random, Plots, DiscreteValueIteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State Structure\n",
    "Define state structure / make initial constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evState"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutable struct evState\n",
    "    p::Vector{Bool} # array of whether cars are present\n",
    "    c::Vector{Int64} # array of charge in each car\n",
    "    renew::Int64 # renewable energy level\n",
    "    t::Int64 # time\n",
    "    done::Bool # are we in a terminal state\n",
    "end\n",
    "\n",
    "# initial state constructor\n",
    "evState(p,c,renew::Int64,t::Int64) = evState(p,c,renew,t,false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MDP Structure\n",
    "Define MDP structure with everything you would need / make initial constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evMDP"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct evMDP <: MDP{evState,Vector{Bool}} \n",
    "    n::Int64 # number of cars\n",
    "    T::Int64 # number of timesteps\n",
    "    renew_levels::Int64 # number of renewable mixture levels, 0:renew_levels\n",
    "    charge_levels::Int64 # number of charge levels, 0:charge_levels\n",
    "    λ::Float64 # terminal reward weighting\n",
    "    addRenewFunc # function handle for adding renewable energy, should be function of t (current time step),T (final time step)\n",
    "end\n",
    "\n",
    "# we use key worded arguments so we can change any of the values we pass in \n",
    "function evMDP(;n::Int64 = 3, # number of cars\n",
    "                T::Int64 = 6, # number of timesteps\n",
    "                renew_levels::Int64 = 3, # number of renewable mixture levels, 0:renew_levels\n",
    "                charge_levels::Int64 = 3, # number of charge levels, 0:charge_levels\n",
    "                λ::Float64 = 10.0, #energy reward weighting\n",
    "                addRenewFunc = addZeroRenew) # function for adding reward \n",
    "    return evMDP(n, T, renew_levels, charge_levels, λ, addRenewFunc)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### States\n",
    "Define all possible states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert number to an array of numbers using requested base system, array length\n",
    "function num2array(number,base,array_length)\n",
    "    base==2 ? finalarray = zeros(Bool, array_length) : finalarray = zeros(Int64, array_length)\n",
    "    idx=1\n",
    "    while number > 0\n",
    "        finalarray[idx] = rem(number,base)\n",
    "        number = div(number,base)\n",
    "        idx+=1\n",
    "    end\n",
    "    return finalarray\n",
    "end\n",
    "\n",
    "function POMDPs.states(mdp::evMDP)\n",
    "    s = [] # initialize an array of GridWorldStates\n",
    "    \n",
    "    # add every possible state. This includes every possible combination of present/charge array\n",
    "    \n",
    "    for iP = 0:(2^mdp.n-1)\n",
    "        present = num2array(iP,2,mdp.n)\n",
    "        \n",
    "        for iC = 0:((mdp.charge_levels+1)^mdp.n-1)\n",
    "            charge = num2array(iC,(mdp.charge_levels+1),mdp.n)\n",
    "            \n",
    "            for rl=0:mdp.renew_levels, t=1:mdp.T\n",
    "            \n",
    "                # if in final time, make sure the done flag is set on\n",
    "                t==mdp.T ? push!(s,evState(present, charge, rl, t, true)) : push!(s,evState(present, charge, rl, t)) \n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return s\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "POMDPs.initialstate(mdp::evMDP, rng::AbstractRNG) = evState(zeros(Bool,mdp.n),zeros(Int64,mdp.n), mdp.renew_levels, 1)\n",
    "POMDPs.initialstate(mdp::evMDP) = POMDPs.initialstate(mdp,MersenneTwister(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actions\n",
    "Define all possible action vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "function POMDPs.actions(mdp::evMDP)\n",
    "    # initialize empty action space a\n",
    "    a = []    \n",
    "    # populate with all combinations of actions, ex [true, false, true, true]\n",
    "    for iA=0:(2^mdp.n-1)\n",
    "        push!(a,num2array(iA,2,mdp.n))\n",
    "    end\n",
    "    return a\n",
    "end\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reward Function\n",
    "Define the reward function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "function POMDPs.reward(mdp::evMDP, state::evState, action::Vector{Bool}, statep::evState)\n",
    "    r = mdp.λ*statep.renew \n",
    "    if statep.done\n",
    "        max_c = mdp.charge_levels\n",
    "        for i in 1:length(state.p)\n",
    "            if state.p[i] == true\n",
    "                r -= exp((max_c-state.c[i])/max_c)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return r\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transition Function\n",
    "Define the next-state transition probabilities (this is the hard one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "carAppearStates (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# chance of a car appearing in any slot at time t given total timescale T\n",
    "carAppearProb(t,T) = 1/(1+exp(-20(t-2)/T))\n",
    "\n",
    "# function takes a state to generate different charge probabilities for, the previous presence array, the mdp, \n",
    "# and the probability of transitioning to \n",
    "function carAppearStates(baseState,prevP,mdp,probability)\n",
    "    \n",
    "    newCarIdxs = findall(baseState.p .!= prevP)\n",
    "    \n",
    "    # distribute probabilities uniformly over possible charge states\n",
    "    probs = zeros(Int64,mdp.charge_levels^length(newCarIdxs)) .+ probability/(mdp.charge_levels^length(newCarIdxs))\n",
    "    \n",
    "    chargeCombs = [baseState.c[:]]\n",
    "    for ind in newCarIdxs\n",
    "        chargeCombsPrev = chargeCombs\n",
    "        \n",
    "        chargeCombs = []\n",
    "        for charge in chargeCombsPrev, level in 0:(mdp.charge_levels-1)\n",
    "            addition = charge[:]\n",
    "            addition[ind] = level\n",
    "            push!(chargeCombs,addition)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    state_vec = evState[]\n",
    "    for charge in chargeCombs\n",
    "        push!(state_vec,evState(baseState.p, charge, baseState.renew, baseState.t, baseState.done))\n",
    "    end\n",
    "    return state_vec, probs\n",
    "end\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching evMDP(::Int64, ::Int64, ::Int64, ::Int64, ::Float64)\nClosest candidates are:\n  evMDP(::Int64, ::Int64, ::Int64, ::Int64, ::Float64, !Matched::Any) at In[3]:2\n  evMDP(::Any, ::Any, ::Any, ::Any, ::Any, !Matched::Any) at In[3]:2",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching evMDP(::Int64, ::Int64, ::Int64, ::Int64, ::Float64)\nClosest candidates are:\n  evMDP(::Int64, ::Int64, ::Int64, ::Int64, ::Float64, !Matched::Any) at In[3]:2\n  evMDP(::Any, ::Any, ::Any, ::Any, ::Any, !Matched::Any) at In[3]:2",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[9]:6"
     ]
    }
   ],
   "source": [
    "prevP = [true, false, true, false]\n",
    "\n",
    "newP = [true, true, true, true]\n",
    "newC = [3, 4, 4, 4]\n",
    "baseState = evState(newP,newC,0,1,false)\n",
    "test_mdp = evMDP(4,4,4,4,0.1)\n",
    "\n",
    "states,probs = carAppearStates(baseState,prevP,test_mdp,1.0)\n",
    "println(states)\n",
    "println(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "getNextPs (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function getNextPs(p,car_prob)\n",
    "    wherenocars = findall(iszero,p)\n",
    "    p_next = [p]\n",
    "    for ind in wherenocars\n",
    "        p_next_prev = p_next\n",
    "        p_next = []\n",
    "        for p in p_next_prev\n",
    "            push!(p_next,p)\n",
    "            state_new = p[:]\n",
    "            state_new[ind] = true\n",
    "            push!(p_next,state_new)        \n",
    "        end\n",
    "    end\n",
    "    \n",
    "    \n",
    "    # calculate probability\n",
    "    num_initial_spaces = length(wherenocars)\n",
    "    num_new_cars = []\n",
    "    for p_check in p_next\n",
    "        n_new_cars = count(p_check .!= p)\n",
    "        push!(num_new_cars,n_new_cars)\n",
    "    end\n",
    "    probs = [(car_prob^n)*(1-car_prob)^(num_initial_spaces-n) for n in num_new_cars]\n",
    "    \n",
    "    return p_next, probs\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any[Bool[true, false, false], Bool[true, false, true], Bool[true, true, false], Bool[true, true, true]]\n",
      "[0.0625, 0.1875, 0.1875, 0.5625]\n"
     ]
    }
   ],
   "source": [
    "p, pr = getNextPs([true, false, false],.75)\n",
    "println(p)\n",
    "println(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "addZeroRenew(t,T) = 0\n",
    "addRenewFirstHalf(t,T) = 1*(t<=T/2)\n",
    "addRenewSecondHalf(t,T) = 1*(t>T/2)\n",
    "\n",
    "function POMDPs.transition(mdp::evMDP, state::evState, action::Vector{Bool})\n",
    "    \n",
    "    # deterministic transitions\n",
    "    \n",
    "    # time and teriminality\n",
    "    t_next = state.t + 1\n",
    "    t_next == mdp.T ? done_bool = true : done_bool = false\n",
    "    \n",
    "    # energy level\n",
    "    renew_next = min(max(0,round.(Int8,state.renew + mdp.addRenewFunc(state.t,mdp.T) - length(findall(action))/mdp.n)),mdp.renew_levels)\n",
    "    # delta_charge = 0.5/4 # Amount of energy lost per charge per car as a fraction of total charge level\n",
    "    #renew_next = min(max(0,round.(Int8,state.renew + mdp.addRenewFunc(state.t,mdp.T) - length(findall(action))*delta_charge*mdp.renew_level),mdp.renew_levels))\n",
    "    \n",
    "    # charge in each car\n",
    "    # c_next = round.(Int8, state.c + action*delta_charge*mdp.renew_levels)\n",
    "    c_next = min.(mdp.charge_levels, state.c + action.*state.p) # increment by one if charge action taken when car present, and cap at max charge\n",
    "    \n",
    "    # probabilistic transitions\n",
    "    \n",
    "    # car presence\n",
    "    appear_prob = carAppearProb(t_next,mdp.T)\n",
    "    p_next, probs = getNextPs(state.p[:],appear_prob)\n",
    "    \n",
    "    # build next state array\n",
    "    next_states = [evState(p_new,c_next,renew_next,t_next,done_bool) for p_new in p_next]\n",
    "    # updated_states, updated_probs = [carAppearStates(baseState,state.p,mdp,probability) for baseState,probability in zip(next_states,probs)] ]\n",
    "    new_states = []\n",
    "    new_probs = Float64[]\n",
    "    \n",
    "    for i in 1:length(next_states)\n",
    "        updated_state, updated_prob = carAppearStates(next_states[i],state.p,mdp,probs[i])\n",
    "        push!(new_states,updated_state...)\n",
    "        push!(new_probs,updated_prob...)\n",
    "    end\n",
    "    \n",
    "    # new_states, new_probs = [s[:],p[:] for s,p in zip(updated_states,updated_probs)]\n",
    "    # add section to incorporate different possible start charges\n",
    "\n",
    "    return SparseCat(new_states,new_probs)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching evMDP(::Int64, ::Int64, ::Int64, ::Int64, ::Float64)\nClosest candidates are:\n  evMDP(::Int64, ::Int64, ::Int64, ::Int64, ::Float64, !Matched::Any) at In[3]:2\n  evMDP(::Any, ::Any, ::Any, ::Any, ::Any, !Matched::Any) at In[3]:2",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching evMDP(::Int64, ::Int64, ::Int64, ::Int64, ::Float64)\nClosest candidates are:\n  evMDP(::Int64, ::Int64, ::Int64, ::Int64, ::Float64, !Matched::Any) at In[3]:2\n  evMDP(::Any, ::Any, ::Any, ::Any, ::Any, !Matched::Any) at In[3]:2",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[13]:1"
     ]
    }
   ],
   "source": [
    "test_mdp = evMDP(4,4,4,4,0.1)\n",
    "\n",
    "\n",
    "P = [true, false, true, false]\n",
    "action = [true, true, true, true]\n",
    "C = [3, 0, 4, 0]\n",
    "baseState = evState(P,C,0,1,false)\n",
    "\n",
    "POMDPs.transition(test_mdp,baseState,action)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Miscellaneous Functions\n",
    "Define other functions that POMDPs.jl needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "POMDPs.n_states(mdp::evMDP) = 2^mdp.n*(mdp.charge_levels+1)^mdp.n*(mdp.renew_levels+1)*mdp.T\n",
    "POMDPs.n_actions(mdp::evMDP) = 2^mdp.n\n",
    "POMDPs.discount(mdp::evMDP) = 1.\n",
    "POMDPs.isterminal(mdp::evMDP, s::evState) = s.done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define state and action indexing\n",
    "function indVal(base, a)\n",
    "    ind = 1\n",
    "    for i in 1:length(a)\n",
    "        ind += a[i]*base^(i-1)\n",
    "    end\n",
    "    return ind\n",
    "end    \n",
    "\n",
    "function POMDPs.stateindex(mdp::evMDP, state::evState)\n",
    "    indP = indVal(2,state.p)\n",
    "    indC = indVal(1+mdp.charge_levels,state.c)\n",
    "    indR = state.renew + 1\n",
    "    indT = state.t\n",
    "    maxP = 2^(mdp.n)\n",
    "    maxC = (mdp.charge_levels + 1)^(mdp.n)\n",
    "    maxR = mdp.renew_levels + 1\n",
    "    maxT = mdp.T\n",
    "    sInd = indP + (maxP*(indC-1)) + (maxC*maxP*(indR-1)) + (maxR*maxC*maxP*(indT-1))\n",
    "    return sInd\n",
    "end\n",
    "\n",
    "function POMDPs.actionindex(mdp::evMDP, act::Vector{Bool})\n",
    "    return indVal(2,act)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Solvers / Simulators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: n not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: n not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[16]:1"
     ]
    }
   ],
   "source": [
    "# initialize the problem\n",
    "mdp = evMDP(n,renew_levels=4)\n",
    "#=Defaults\n",
    "n::Int64 = 3, # number of cars\n",
    "T::Int64 = 6, # number of timesteps         \n",
    "renew_levels::Int64 = 3, # number of renewable mixture levels, 0:renew_levels\n",
    "charge_levels::Int64 = 3, # number of charge levels, 0:charge_levels\n",
    "λ::Float64 = 10.0)\n",
    "=#\n",
    "@requirements_info ValueIterationSolver() mdp\n",
    "\n",
    "\n",
    "solver = ValueIterationSolver(max_iterations=100, belres=1e-6, verbose=true) # initializes the Solver type\n",
    "policy = solve(solver, mdp) # runs value iterations\n",
    "\n",
    "# initialize the policy by passing in your problem\n",
    "# policy = ValueIterationPolicy(mdp) \n",
    "\n",
    "# solve for an optimal policy\n",
    "# if verbose=false, the text output will be supressed (false by default)\n",
    "# solve(solver, mdp, policy, verbose=true);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "simulate_evMDP (generic function with 1 method)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solve_evMDP(mdp) = solve(ValueIterationSolver(max_iterations=100, belres=1e-6, verbose=true), mdp)\n",
    "\n",
    "function simulate_evMDP(mdp,policy;seed=1)\n",
    "    history = simulate(HistoryRecorder(max_steps=100,rng = MersenneTwister(seed)), mdp, policy, POMDPs.initialstate(mdp))\n",
    "\n",
    "    counter = 0\n",
    "    ev = zeros(Int8,mdp.T-1,mdp.n)\n",
    "    # look at what happened\n",
    "    for (s, a, r) in eachstep(history, \"(s, a, r)\")\n",
    "        counter +=1\n",
    "        ev[counter,:] = s.c + s.p .- 1\n",
    "        println(\"State was $s,\")\n",
    "        println(\"Reward was $r,\")\n",
    "        println(\"action $a was taken,\")\n",
    "    end\n",
    "    return ev\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: mdp not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: mdp not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[18]:1"
     ]
    }
   ],
   "source": [
    "ev = simulate_evMDP(mdp,policy,seed=5)\n",
    "heatmap(ev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example initializing, solving, simulating, and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 1   ] residual:        150 | iteration runtime:   4194.960 ms, (      4.19 s total)\n",
      "[Iteration 2   ] residual:        150 | iteration runtime:   3973.028 ms, (      8.17 s total)\n",
      "[Iteration 3   ] residual:        150 | iteration runtime:   3517.122 ms, (      11.7 s total)\n",
      "[Iteration 4   ] residual:        150 | iteration runtime:   3479.505 ms, (      15.2 s total)\n",
      "[Iteration 5   ] residual:        150 | iteration runtime:   3454.433 ms, (      18.6 s total)\n",
      "[Iteration 6   ] residual:        147 | iteration runtime:   5017.243 ms, (      23.6 s total)\n",
      "[Iteration 7   ] residual:          0 | iteration runtime:   4374.227 ms, (        28 s total)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ValueIterationPolicy{Float64}([-3.01083 -3.01083 … -3.01083 -3.01083; -3.00722 -3.00722 … -3.00722 -3.00722; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [-3.01083, -3.00722, -3.00722, -3.00361, -3.00722, -3.00361, -3.00361, -3.0, -3.01083, -3.00722  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1  …  1, 1, 1, 1, 1, 1, 1, 1, 1, 1], Array{Bool,1}[[false, false, false], [true, false, false], [false, true, false], [true, true, false], [false, false, true], [true, false, true], [false, true, true], [true, true, true]], true, evMDP(3, 7, 3, 3, 50.0, addZeroRenew))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mdp = evMDP(λ=50.,T=7)\n",
    "policy = solve_evMDP(test_mdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State was evState(Bool[false, false, false], [0, 0, 0], 3, 1, false),\n",
      "Reward was 150.0,\n",
      "action Bool[false, false, false] was taken,\n",
      "State was evState(Bool[false, true, true], [0, 0, 2], 3, 2, false),\n",
      "Reward was 150.0,\n",
      "action Bool[false, true, false] was taken,\n",
      "State was evState(Bool[true, true, true], [1, 1, 2], 3, 3, false),\n",
      "Reward was 150.0,\n",
      "action Bool[true, false, false] was taken,\n",
      "State was evState(Bool[true, true, true], [2, 1, 2], 3, 4, false),\n",
      "Reward was 150.0,\n",
      "action Bool[true, false, false] was taken,\n",
      "State was evState(Bool[true, true, true], [3, 1, 2], 3, 5, false),\n",
      "Reward was 150.0,\n",
      "action Bool[false, true, false] was taken,\n",
      "State was evState(Bool[true, true, true], [3, 2, 2], 3, 6, false),\n",
      "Reward was 146.20877514982783,\n",
      "action Bool[false, false, false] was taken,\n"
     ]
    }
   ],
   "source": [
    "ev = simulate_evMDP(test_mdp,policy,seed=11)\n",
    "\n",
    "heatmap(ev)\n",
    "title!(\"Charge level in $(test_mdp.n)-car simulation with lambda = $(test_mdp.λ)\")\n",
    "yaxis!(\"Time step\")\n",
    "xaxis!(\"Car Number\")\n",
    "xticks!(1:test_mdp.n)\n",
    "savefig(\"NoSunLambda50.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 1   ] residual:       8.15 | iteration runtime:   4219.489 ms, (      4.22 s total)\n",
      "[Iteration 2   ] residual:       6.38 | iteration runtime:   3504.327 ms, (      7.72 s total)\n",
      "[Iteration 3   ] residual:       5.61 | iteration runtime:   3521.447 ms, (      11.2 s total)\n",
      "[Iteration 4   ] residual:       4.84 | iteration runtime:   3867.667 ms, (      15.1 s total)\n",
      "[Iteration 5   ] residual:       4.29 | iteration runtime:   3543.263 ms, (      18.7 s total)\n",
      "[Iteration 6   ] residual:       3.74 | iteration runtime:   3456.291 ms, (      22.1 s total)\n",
      "[Iteration 7   ] residual:          0 | iteration runtime:   3518.146 ms, (      25.6 s total)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ValueIterationPolicy{Float64}([-3.01083 -3.01083 … -3.01083 -3.01083; -3.00722 -3.00722 … -3.00722 -3.00722; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [-3.01083, -3.00722, -3.00722, -3.00361, -3.00722, -3.00361, -3.00361, -3.0, -3.01083, -3.00722  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1  …  1, 1, 1, 1, 1, 1, 1, 1, 1, 1], Array{Bool,1}[[false, false, false], [true, false, false], [false, true, false], [true, true, false], [false, false, true], [true, false, true], [false, true, true], [true, true, true]], true, evMDP(3, 7, 3, 3, 1.0, addZeroRenew))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mdp = evMDP(λ=1.,T=7)\n",
    "policy = solve_evMDP(test_mdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State was evState(Bool[false, false, false], [0, 0, 0], 3, 1, false),\n",
      "Reward was 3.0,\n",
      "action Bool[false, false, false] was taken,\n",
      "State was evState(Bool[false, true, true], [0, 0, 2], 3, 2, false),\n",
      "Reward was 3.0,\n",
      "action Bool[false, true, false] was taken,\n",
      "State was evState(Bool[true, true, true], [1, 1, 2], 3, 3, false),\n",
      "Reward was 3.0,\n",
      "action Bool[true, false, false] was taken,\n",
      "State was evState(Bool[true, true, true], [2, 1, 2], 3, 4, false),\n",
      "Reward was 3.0,\n",
      "action Bool[true, false, false] was taken,\n",
      "State was evState(Bool[true, true, true], [3, 1, 2], 3, 5, false),\n",
      "Reward was 3.0,\n",
      "action Bool[false, true, false] was taken,\n",
      "State was evState(Bool[true, true, true], [3, 2, 2], 3, 6, false),\n",
      "Reward was -0.791224850172179,\n",
      "action Bool[false, false, false] was taken,\n"
     ]
    }
   ],
   "source": [
    "ev = simulate_evMDP(test_mdp,policy,seed=11)\n",
    "\n",
    "heatmap(ev)\n",
    "title!(\"Charge level in $(test_mdp.n)-car simulation with lambda = $(test_mdp.λ)\")\n",
    "yaxis!(\"Time step\")\n",
    "xaxis!(\"Car Number\")\n",
    "xticks!(1:test_mdp.n)\n",
    "savefig(\"NoSunLambda1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 1   ] residual:       8.15 | iteration runtime:   4061.370 ms, (      4.06 s total)\n",
      "[Iteration 2   ] residual:       6.06 | iteration runtime:   3725.500 ms, (      7.79 s total)\n",
      "[Iteration 3   ] residual:       4.35 | iteration runtime:   3574.845 ms, (      11.4 s total)\n",
      "[Iteration 4   ] residual:       3.42 | iteration runtime:   3570.414 ms, (      14.9 s total)\n",
      "[Iteration 5   ] residual:       3.06 | iteration runtime:   7285.177 ms, (      22.2 s total)\n",
      "[Iteration 6   ] residual:       3.03 | iteration runtime:   4116.010 ms, (      26.3 s total)\n",
      "[Iteration 7   ] residual:          0 | iteration runtime:   3510.401 ms, (      29.8 s total)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ValueIterationPolicy{Float64}([-3.01083 -3.01083 … -3.01083 -3.01083; -3.00722 -3.00722 … -3.00722 -3.00722; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [-3.01083, -3.00722, -3.00722, -3.00361, -3.00722, -3.00361, -3.00361, -3.0, -3.01083, -3.00722  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1  …  1, 1, 1, 1, 1, 1, 1, 1, 1, 1], Array{Bool,1}[[false, false, false], [true, false, false], [false, true, false], [true, true, false], [false, false, true], [true, false, true], [false, true, true], [true, true, true]], true, evMDP(3, 7, 3, 3, 0.01, addZeroRenew))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mdp = evMDP(λ=0.01,T=7)\n",
    "policy = solve_evMDP(test_mdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State was evState(Bool[false, false, false], [0, 0, 0], 3, 1, false),\n",
      "Reward was 0.03,\n",
      "action Bool[false, false, false] was taken,\n",
      "State was evState(Bool[false, true, true], [0, 0, 2], 3, 2, false),\n",
      "Reward was 0.03,\n",
      "action Bool[false, true, false] was taken,\n",
      "State was evState(Bool[true, true, true], [1, 1, 2], 3, 3, false),\n",
      "Reward was 0.03,\n",
      "action Bool[true, false, false] was taken,\n",
      "State was evState(Bool[true, true, true], [2, 1, 2], 3, 4, false),\n",
      "Reward was 0.03,\n",
      "action Bool[false, true, false] was taken,\n",
      "State was evState(Bool[true, true, true], [2, 2, 2], 3, 5, false),\n",
      "Reward was 0.02,\n",
      "action Bool[true, true, true] was taken,\n",
      "State was evState(Bool[true, true, true], [3, 3, 3], 2, 6, false),\n",
      "Reward was -2.98,\n",
      "action Bool[false, false, false] was taken,\n"
     ]
    }
   ],
   "source": [
    "ev = simulate_evMDP(test_mdp,policy,seed=11)\n",
    "\n",
    "heatmap(ev)\n",
    "title!(\"Charge level in $(test_mdp.n)-car simulation with lambda = $(test_mdp.λ)\")\n",
    "yaxis!(\"Time step\")\n",
    "xaxis!(\"Car Number\")\n",
    "xticks!(1:test_mdp.n)\n",
    "savefig(\"NoSunLambda0p1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evMDP(3, 7, 3, 3, 0.01, addZeroRenew)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SparseCat{Array{Any,1},Array{Float64,1}}(Any[evState(Bool[true, true, true], [2, 2, 2], 2, 6, false)], [1.0])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "println(test_mdp)\n",
    "state = evState(Bool[true, true, true], [1, 1, 2], 3, 5, false)\n",
    "action = Bool[true, true, false]\n",
    "POMDPs.transition(test_mdp,state,action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 1   ] residual:        150 | iteration runtime:   3512.654 ms, (      3.51 s total)\n",
      "[Iteration 2   ] residual:        150 | iteration runtime:   3838.480 ms, (      7.35 s total)\n",
      "[Iteration 3   ] residual:        150 | iteration runtime:   3898.921 ms, (      11.3 s total)\n",
      "[Iteration 4   ] residual:        150 | iteration runtime:   5081.486 ms, (      16.3 s total)\n",
      "[Iteration 5   ] residual:        150 | iteration runtime:   5538.656 ms, (      21.9 s total)\n",
      "[Iteration 6   ] residual:        147 | iteration runtime:   6062.133 ms, (      27.9 s total)\n",
      "[Iteration 7   ] residual:          0 | iteration runtime:   4985.911 ms, (      32.9 s total)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ValueIterationPolicy{Float64}([746.108 746.108 … 446.108 446.108; 745.744 746.191 … 445.744 446.191; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [746.108, 746.191, 746.191, 745.761, 746.191, 745.761, 745.761, 745.261, 746.108, 746.556  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1, 2, 3, 2, 5, 2, 3, 2, 1, 2  …  1, 1, 1, 1, 1, 1, 1, 1, 1, 1], Array{Bool,1}[[false, false, false], [true, false, false], [false, true, false], [true, true, false], [false, false, true], [true, false, true], [false, true, true], [true, true, true]], true, evMDP(3, 7, 3, 3, 50.0, addRenewFirstHalf))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# addRenewFunc options: addZeroRenew (default), addRenewFirstHalf, addRenewSecondHalf\n",
    "test_mdp = evMDP(λ=50.,T=7,addRenewFunc = addRenewFirstHalf)\n",
    "policy = solve_evMDP(test_mdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State was evState(Bool[false, false, false], [0, 0, 0], 3, 1, false),\n",
      "Reward was 150.0,\n",
      "action Bool[false, false, false] was taken,\n",
      "State was evState(Bool[false, true, true], [0, 0, 2], 3, 2, false),\n",
      "Reward was 150.0,\n",
      "action Bool[false, true, false] was taken,\n",
      "State was evState(Bool[true, true, true], [1, 1, 2], 3, 3, false),\n",
      "Reward was 150.0,\n",
      "action Bool[true, true, true] was taken,\n",
      "State was evState(Bool[true, true, true], [2, 2, 3], 3, 4, false),\n",
      "Reward was 150.0,\n",
      "action Bool[true, false, false] was taken,\n",
      "State was evState(Bool[true, true, true], [3, 2, 3], 3, 5, false),\n",
      "Reward was 150.0,\n",
      "action Bool[false, true, false] was taken,\n",
      "State was evState(Bool[true, true, true], [3, 3, 3], 3, 6, false),\n",
      "Reward was 147.0,\n",
      "action Bool[false, false, false] was taken,\n"
     ]
    }
   ],
   "source": [
    "ev = simulate_evMDP(test_mdp,policy,seed=11)\n",
    "\n",
    "heatmap(ev)\n",
    "title!(\"Charge level with lambda = $(test_mdp.λ), added renewables\")\n",
    "yaxis!(\"Time step\")\n",
    "xaxis!(\"Car Number\")\n",
    "xticks!(1:test_mdp.n)\n",
    "savefig(\"SunnyFirstHalf.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14336"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length(POMDPs.states(test_mdp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.0",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
